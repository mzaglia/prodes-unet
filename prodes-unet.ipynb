{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave, imread\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "K.set_image_data_format('channels_last') \n",
    "\n",
    "data_path = 'raw/'\n",
    "\n",
    "image_rows = 256\n",
    "image_cols = 256\n",
    "n_classes = 8\n",
    "smooth = 1.\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = os.path.join(data_path, 'train')\n",
    "annotation_data_path = os.path.join(data_path, 'annotations')\n",
    "\n",
    "images = os.listdir(train_data_path)\n",
    "total = len(images)\n",
    "\n",
    "imgs = np.ndarray((total, image_rows, image_cols, 3), dtype=np.float32)\n",
    "imgs_mask = np.ndarray((total, image_rows, image_cols), dtype=np.byte)\n",
    "\n",
    "i = 0\n",
    "print('-'*30)\n",
    "print('Creating training images...')\n",
    "print('-'*30)\n",
    "for image_name in images:\n",
    "    img = imread(os.path.join(train_data_path, image_name))\n",
    "    img_mask = imread(os.path.join(annotation_data_path, image_name), as_gray=True)\n",
    "\n",
    "    img = np.array([img])\n",
    "    img_mask = np.array([img_mask])\n",
    "\n",
    "    imgs[i] = img\n",
    "    imgs_mask[i] = img_mask\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print('Done: {0}/{1} images'.format(i, total))\n",
    "    i += 1\n",
    "print('Loading done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_train, imgs_test, imgs_mask_train, imgs_mask_test = train_test_split(imgs, imgs_mask, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('imgs_train.npy', imgs_train)\n",
    "np.save('imgs_mask_train.npy', imgs_mask_train)\n",
    "np.save('imgs_test.npy', imgs_test)\n",
    "np.save('imgs_mask_test.npy', imgs_mask_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del imgs_train\n",
    "del imgs_mask_train\n",
    "del imgs_test\n",
    "del imgs_mask_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgs_train = np.load('imgs_train.npy')\n",
    "imgs_mask_train = np.load('imgs_mask_train.npy')\n",
    "\n",
    "mean = np.mean(imgs_train)  # mean for data centering\n",
    "std = np.std(imgs_train)  # std for data normalization\n",
    "\n",
    "imgs_train -= mean\n",
    "imgs_train /= std\n",
    "\n",
    "imgs_mask_train = to_categorical(imgs_mask_train, num_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNet(input_shape=(256, 256, 3), classes=1):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    pool1 = Dropout(0.25)(pool1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    pool2 = Dropout(0.5)(pool2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    pool3 = Dropout(0.5)(pool3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    pool4 = Dropout(0.5)(pool4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    up6 = Dropout(0.5)(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    up7 = Dropout(0.5)(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    up8 = Dropout(0.5)(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    up9 = Dropout(0.5)(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(classes, (1, 1), activation='softmax')(conv9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(classes=n_classes)\n",
    "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=[dice_coef])\n",
    "\n",
    "early_stopping = EarlyStopping(patience=10, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*30)\n",
    "print('Fitting model...')\n",
    "print('-'*30)\n",
    "model.fit(imgs_train, imgs_mask_train, batch_size=12, epochs=100, verbose=1, shuffle=True,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[model_checkpoint, early_stopping, reduce_lr, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del imgs_train\n",
    "del imgs_mask_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_test = np.load('imgs_test.npy')\n",
    "imgs_mask_test = np.load('imgs_mask_test.npy')\n",
    "\n",
    "mean = np.mean(imgs_test)\n",
    "std = np.std(imgs_test)\n",
    "\n",
    "imgs_test -= mean\n",
    "imgs_test /= std\n",
    "\n",
    "imgs_mask_test = to_categorical(imgs_mask_test, num_classes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgs_mask_predict = model.predict(imgs_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "\n",
    "def discrete_cmap(N, base_cmap=None):\n",
    "    \"\"\"Create an N-bin discrete colormap from the specified input map\"\"\"\n",
    "\n",
    "    # Note that if base_cmap is a string or None, you can simply do\n",
    "    #    return plt.cm.get_cmap(base_cmap, N)\n",
    "    # The following works for string, None, or a colormap instance:\n",
    "\n",
    "    base = plt.cm.get_cmap(base_cmap)\n",
    "    color_list = base(np.linspace(0, 1, N))\n",
    "    cmap_name = base.name + str(N)\n",
    "    return base.from_list(cmap_name, color_list, N)\n",
    "\n",
    "pred_dir = 'preds'\n",
    "if not os.path.exists(pred_dir):\n",
    "    os.mkdir(pred_dir)\n",
    "    \n",
    "imgs_test = np.load('imgs_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=True)\n",
    "\n",
    "for img_id in range(len(imgs_mask_predict)):\n",
    "    f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(ncols=2,nrows=2,figsize=(8,8))\n",
    "\n",
    "    labels = [r'FLORESTA', r'DESMATAMENTO', r'HIDROGRAFIA', r'RESIDUO', r'NUVEM', r'NAO\\_FLORESTA2', r'NAO\\_FLORESTA']\n",
    "\n",
    "    c = plt.get_cmap('jet', n_classes)\n",
    "\n",
    "    img_mask_test = np.argmax(imgs_mask_test[img_id], axis = 2)\n",
    "    img_mask_predict = np.argmax(imgs_mask_predict[img_id], axis = 2)\n",
    "\n",
    "    im1 = ax1.imshow(imgs_test[img_id].astype(np.uint32))\n",
    "    ax1.set_title(r'\\centering\\sffamily\\bfseries (a) Imagem Original', x=.5, y=-.15)\n",
    "\n",
    "    im2 = ax2.imshow(img_mask_test, cmap=c).set_clim(0, n_classes - 1)\n",
    "    ax2.set_title(r'\\centering\\sffamily\\bfseries (b) Label Original', x=.5, y=-.15)\n",
    "    \n",
    "    im3 = ax3.imshow(imgs_test[img_id].astype(np.uint32), alpha=0.5)\n",
    "    ax3.imshow(np.argmax(imgs_mask_predict[img_id], axis = 2), alpha=0.7, cmap='gray') # OVERLAY\n",
    "    ax3.set_title(r'\\centering\\sffamily\\bfseries (c) Imagem Original + Label Rede Neural', x=.5, y=-.15)\n",
    "\n",
    "    im4 = ax4.imshow(img_mask_predict, cmap=c).set_clim(0, n_classes - 1)\n",
    "    \n",
    "    ax4.set_title(r'\\centering\\sffamily\\bfseries (d) Label Rede Neural', x=.5, y=-.15)\n",
    "    \n",
    "    colors = [c(value + 1) for value in np.arange(0, n_classes)]\n",
    "    patches = [ mpatches.Patch(color=colors[i], label=\"{l}\".format(l=labels[i]) ) for i in range(len(labels)) ]\n",
    "    \n",
    "    plt.draw()\n",
    "\n",
    "\n",
    "\n",
    "    lgd = f.legend(borderaxespad=0, handles=patches, loc='center')\n",
    "\n",
    "    bb = lgd.get_bbox_to_anchor().inverse_transformed(ax2.transAxes)\n",
    "    xOffset = 1.5\n",
    "    bb.x0 += xOffset\n",
    "    bb.x1 += xOffset\n",
    "    lgd.set_bbox_to_anchor(bb, transform = ax2.transAxes)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    f.savefig('graphs/graph_{}.png'.format(img_id), format='png', bbox_extra_artists=(lgd,), bbox_inches='tight', dpi=300)\n",
    "    plt.close(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# i=0\n",
    "# for image_pred, image_mask_test, image_test in zip(imgs_mask_predict, imgs_mask_test, imgs_test): \n",
    "#     imsave(os.path.join(pred_dir, str(i) +'.png'), image_test.astype(np.uint8))\n",
    "#     imsave(os.path.join(pred_dir, str(i) +'_label.png'), np.argmax(image_mask_test, axis = 2).astype(np.uint8) * (255 // n_classes))\n",
    "#     imsave(os.path.join(pred_dir, str(i) +'_pred.png'), np.argmax(image_pred, axis = 2) * (255// n_classes))\n",
    "#     i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
